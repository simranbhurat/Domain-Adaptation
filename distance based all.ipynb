{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d40144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# transformers is not preinstalled in google colab\n",
    "# !pip install transformers\n",
    "\n",
    "# weights and biases is not preinstalled in google colab\n",
    "# !pip install wandb -q\n",
    "\n",
    "# jupyter setup\n",
    "# % commands are \"jupyter notbook commands\" - %matplotlib inline allows for inline plotting\n",
    "%matplotlib inline\n",
    " \n",
    "# import modules\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers \n",
    "# import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7c876a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set parameters\n",
    "parameter_dict = {\n",
    "    'huggingface_model': 'bert-base-uncased', \n",
    "    'epochs' : 4,\n",
    "    'batch_size': 10,\n",
    "    'dropout_finetune': 0.2,\n",
    "    'learning_rate_AdamW': 2e-5,\n",
    "    'metadata_embedding_size': 128,\n",
    "    'hidden_layer_size': 2048,\n",
    "    'seed': 101\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "584763a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = f\"{parameter_dict['huggingface_model']}-with-metadata-2hidden_layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87b65888",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google made 2 GPU available for this notebook.\n",
      "GPU type: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "# Set up torch for colab\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda') # specify the GPU we want to use in torch\n",
    "  print('Google made {} GPU available for this notebook.'.format(torch.cuda.device_count()))\n",
    "  print('GPU type: {}'.format(torch.cuda.get_device_name()))\n",
    "else:\n",
    "  print('CPU must be used')\n",
    "  device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ed144ab-82c4-4bc7-b288-b830adef8774",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rd = pd.read_csv(\"abstract_title_text_RD.csv\", nrows = 4000)\n",
    "rd = rd[rd['language'] == 'en']\n",
    "rd = rd.dropna()\n",
    "rd = rd.reset_index(drop=True)\n",
    "rd['text_all'] = rd['title'].astype(str) + ',' + rd['abstract'].astype(str) + ',' + rd['text'].astype(str)\n",
    "# metadata: review year ids\n",
    "rd['year'] = pd.to_datetime(rd['date']).dt.year\n",
    "year_dict = {k: k-rd['year'].min() for k in rd['year'].unique()}\n",
    "rd['year_ids'] = rd['year'].replace(year_dict)\n",
    "test_data = rd\n",
    "# tranform data to lists\n",
    "feature_text_target, feature_year_target = test_data['text_all'].to_list(), test_data['year_ids'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d820d927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_data_df = pd.read_csv(path_to_input.format('sample_data.csv'))\n",
    "sample_data_df = pd.read_csv('sample_data.csv', nrows = 4000)\n",
    "possible_labels = sample_data_df['cpc_class'].unique()\n",
    "\n",
    "numerical_encoding_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    numerical_encoding_dict[possible_label] = index\n",
    "\n",
    "sample_data_df['cpc_class_numerical'] = sample_data_df['cpc_class'].replace(numerical_encoding_dict)\n",
    "\n",
    "sample_data_df['text'] = sample_data_df['patent_title'].astype(str) + ',' + sample_data_df['patent_abstract'].astype(str) + ',' + sample_data_df['summary_text'].astype(str)\n",
    "\n",
    "# metadata: review year ids\n",
    "sample_data_df['year'] = pd.to_datetime(sample_data_df['patent_date']).dt.year\n",
    "year_dict = {k: k-sample_data_df['year'].min() for k in sample_data_df['year'].unique()}\n",
    "sample_data_df['year_ids'] = sample_data_df['year'].replace(year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43d2db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation test hold out split\n",
    "# test size\n",
    "test_size = 0.2\n",
    "\n",
    "# validation size\n",
    "val_size = 0.2\n",
    "\n",
    "# training size\n",
    "train_size = 0.6\n",
    "\n",
    "training_data, test_data = sklearn.model_selection.train_test_split(sample_data_df, test_size=test_size, random_state=parameter_dict['seed'])\n",
    "training_data, validation_data = sklearn.model_selection.train_test_split(training_data, test_size=val_size/(1-test_size), random_state=parameter_dict['seed'])\n",
    "# del all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134724a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform data to lists\n",
    "feature_text_train, feature_year_train, labels_train = training_data['text'].to_list(), training_data['year_ids'].to_list(), training_data['cpc_class_numerical'].to_list()\n",
    "feature_text_validation, feature_year_validation, labels_validation = validation_data['text'].to_list(), validation_data['year_ids'].to_list(), validation_data['cpc_class_numerical'].to_list()\n",
    "feature_text_test, feature_year_test, labels_test = test_data['text'].to_list(), test_data['year_ids'].to_list(), test_data['cpc_class_numerical'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "077f4525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassificationMetadata(transformers.BertPreTrainedModel):\n",
    "    def __init__(self, config, num_year_ids, metadata_embedding_size, hidden_layer_size, dropout_fine_tune):\n",
    "        super().__init__(config)\n",
    "        self.bert = transformers.BertModel(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_fine_tune)\n",
    "\n",
    "        \n",
    "        self.embedding_year = nn.Embedding(num_year_ids, metadata_embedding_size) #32, 128       \n",
    "        self.layer_normalizer = nn.LayerNorm(768 + metadata_embedding_size) # 896\n",
    "        self.fc1_hidden = nn.Linear(768 + metadata_embedding_size, hidden_layer_size)#896 , 2048\n",
    "        self.fc2_hidden = nn.Linear(hidden_layer_size, hidden_layer_size)#2048 , 2048\n",
    "        self.fc_classifier = nn.Linear(hidden_layer_size, config.num_labels)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        year_ids: Optional[torch.Tensor] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], transformers.modeling_outputs.SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=True,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        year_embedding = self.embedding_year(year_ids)\n",
    "\n",
    "        pooled_bert_output = outputs[1]\n",
    "        \n",
    "        # print(pooled_bert_output.size(), year_embedding.size())\n",
    "        \n",
    "        # concat\n",
    "        input_classification_head = torch.cat((pooled_bert_output, year_embedding), dim=1)#32, 1024\n",
    "\n",
    "        # fc1\n",
    "        input_fc1_hidden = self.dropout(self.layer_normalizer(input_classification_head))#32, 1024\n",
    "        output_fc1_hidden = self.fc1_hidden(input_fc1_hidden)# 32, 768\n",
    "\n",
    "        # fc2\n",
    "        input_fc2_hidden = torch.relu(self.dropout(output_fc1_hidden))\n",
    "        output_fc2_hidden = self.fc2_hidden(input_fc2_hidden) #32, 768\n",
    "\n",
    "        # logit classifier\n",
    "        input_fc_classifier = torch.relu(self.dropout(output_fc2_hidden))\n",
    "        logits = self.fc_classifier(input_fc_classifier)\n",
    "\n",
    "        # loss\n",
    "        # loss_fct = nn.CrossEntropyLoss()\n",
    "        # loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        # loss\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        else:\n",
    "            loss = None\n",
    "            \n",
    "        return transformers.modeling_outputs.SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6db8c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the pre-treained BERT Tokenizer\n",
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Apply the tokenizer to the datasets\n",
    "feature_text_train = bert_tokenizer(feature_text_train, padding='max_length', max_length=400, truncation =True, return_tensors='pt')\n",
    "feature_text_validation = bert_tokenizer(feature_text_validation, padding='max_length', max_length=400, truncation =True, return_tensors='pt')\n",
    "feature_text_test = bert_tokenizer(feature_text_test, padding='max_length', max_length=400, truncation =True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64bc6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer examples\n",
    "# print('Example of the BERT tokenizer: \\n \\t {}'.format(bert_tokenizer.decode(feature_text_train.data['input_ids'][2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99ae74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader for transformers\n",
    "class AttributeDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tokenized_text: torch.Tensor, year_ids, labels):\n",
    "    self.tokenized_features = tokenized_text\n",
    "    self.year_ids = torch.tensor(year_ids)\n",
    "    self.labels = torch.tensor(labels)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.tokenized_features.items()}\n",
    "    item['year_ids'] = self.year_ids[idx]\n",
    "    item['labels'] = self.labels[idx]\n",
    "    return item\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "train_torch = AttributeDataset(feature_text_train, feature_year_train, labels_train)\n",
    "validation_torch = AttributeDataset(feature_text_validation, feature_year_validation, labels_validation)\n",
    "test_torch = AttributeDataset(feature_text_test, feature_year_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04f72687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertClassificationMetadata: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertClassificationMetadata from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertClassificationMetadata from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertClassificationMetadata were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['embedding_year.weight', 'layer_normalizer.bias', 'layer_normalizer.weight', 'fc1_hidden.weight', 'fc_classifier.weight', 'fc2_hidden.weight', 'fc_classifier.bias', 'fc2_hidden.bias', 'fc1_hidden.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Batches: 240\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained BERT model and push it to the GPU memory\n",
    "\n",
    "#bert_classification_model = transformers.BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(numerical_encoding_dict))\n",
    "bert_classification_model = BertClassificationMetadata.from_pretrained('bert-base-uncased', num_labels=len(numerical_encoding_dict), num_year_ids = max(year_dict.keys()), metadata_embedding_size=parameter_dict['metadata_embedding_size'], hidden_layer_size=parameter_dict['hidden_layer_size'], dropout_fine_tune=parameter_dict['dropout_finetune'])\n",
    "\n",
    "# model to GPU\n",
    "bert_classification_model.to(device)\n",
    "\n",
    "# Define the data loader for batching, batch size 16 seems to work well\n",
    "# (higher would cause memory overflow problems on the GPU)\n",
    "train_data_loader = torch.utils.data.DataLoader(train_torch, batch_size=parameter_dict['batch_size'], shuffle=True)\n",
    "validation_data_loader = torch.utils.data.DataLoader(validation_torch, batch_size=parameter_dict['batch_size'], shuffle=True)\n",
    "number_of_batches = len(train_data_loader)\n",
    "print(f'Number of Batches: {number_of_batches}')\n",
    "\n",
    "# Setup the ADAM optimizer with generic parameters.\n",
    "optimizer = torch.optim.AdamW(bert_classification_model.parameters(), lr=parameter_dict['learning_rate_AdamW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91de648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the pre-treained BERT Tokenizer\n",
    "bert_tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Apply the tokenizer to the datasets\n",
    "feature_text_target= bert_tokenizer(feature_text_target, padding='max_length', max_length=400, truncation =True, return_tensors='pt')\n",
    "\n",
    "# data loader for transformers\n",
    "class AttributeDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tokenized_text: torch.Tensor, year_ids):\n",
    "    self.tokenized_features = tokenized_text\n",
    "    self.year_ids = torch.tensor(year_ids)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    item = {key: val[idx] for key, val in self.tokenized_features.items()}\n",
    "    item['year_ids'] = self.year_ids[idx]\n",
    "    return item\n",
    "\n",
    "  def __len__(self):\n",
    "    return rd.shape[0]\n",
    "\n",
    "target_torch = AttributeDataset(feature_text_target, feature_year_target)\n",
    "target_dataloader = torch.utils.data.DataLoader(target_torch, batch_size=parameter_dict['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fa0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# milestones\n",
    "def training_milestone(number_of_milestones, number_of_batches):\n",
    "  batches_per_milestone = (number_of_batches-1)/number_of_milestones\n",
    "  milestone_list = [int(x*batches_per_milestone) for x in range(1, number_of_milestones)]\n",
    "  milestone_list.append(number_of_batches-1)\n",
    "  return milestone_list\n",
    "\n",
    "training_milestones = training_milestone(16, number_of_batches)\n",
    "\n",
    "# validation\n",
    "validation_milestones = training_milestone(4, number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab64822-8c32-46ac-9f73-afe37be6ad3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mmd_loss(hidden_states_source, hidden_states_target, sigma):\n",
    "    # Compute the mean embeddings of the source and target domains\n",
    "    mean_source = torch.mean(hidden_states_source, dim=0)\n",
    "    mean_target = torch.mean(hidden_states_target, dim=0)\n",
    "\n",
    "    # Compute the MMD between the source and target domains\n",
    "    mmd = 0\n",
    "    for i in range(hidden_states_source.shape[0]):\n",
    "        for j in range(hidden_states_target.shape[0]):\n",
    "            dist = torch.sum(torch.square(hidden_states_source[i] - hidden_states_target[j]))\n",
    "            mmd += torch.exp(-dist / (2 * sigma ** 2))\n",
    "\n",
    "    return mmd / (hidden_states_source.shape[0] * hidden_states_target.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff396bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------- Start Training -------------------------\n",
      "------------------------------------------------------------------\n",
      "Epoch: 0\tBatch: 239\tTrain-Loss: 2.953341007232666\n",
      "------------------------------------------------------------------\n",
      "Validation Run 0 (Epoch 0):\n",
      "\t0\n",
      "\t Val-Loss: \t309.0259094238281\n",
      "\t Val-Accu: \t0.3449999988079071\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!! New best Model !!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------------------------\n",
      "Resume Training:\n",
      "Epoch: 1\tBatch: 239\tTrain-Loss: 1.5150697231292725\n",
      "------------------------------------------------------------------\n",
      "Validation Run 1 (Epoch 1):\n",
      "\t1\n",
      "\t Val-Loss: \t232.5215606689453\n",
      "\t Val-Accu: \t0.5149999856948853\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!! New best Model !!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------------------------\n",
      "Resume Training:\n",
      "Epoch: 2\tBatch: 239\tTrain-Loss: 2.087878465652466\n",
      "------------------------------------------------------------------\n",
      "Validation Run 2 (Epoch 2):\n",
      "\t2\n",
      "\t Val-Loss: \t207.57122802734375\n",
      "\t Val-Accu: \t0.5462499856948853\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!! New best Model !!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------------------------\n",
      "Resume Training:\n",
      "Epoch: 3\tBatch: 239\tTrain-Loss: 1.7416995763778687\n",
      "------------------------------------------------------------------\n",
      "Validation Run 3 (Epoch 3):\n",
      "\t3\n",
      "\t Val-Loss: \t198.99923706054688\n",
      "\t Val-Accu: \t0.5799999833106995\n",
      "!!!!!!!!!!!!!!!!!!!!!!!!! New best Model !!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "------------------------------------------------------------------\n",
      "Resume Training:\n",
      "The Training took:  342.5743215084076 Seconds\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "start_time = time.time()\n",
    "# initialize training\n",
    "bert_classification_model.train()\n",
    "# first loss to high values to not save model\n",
    "sum_of_val_loss_min = 9999\n",
    "# iterator for the number of validation runs\n",
    "val_run_iter = 0\n",
    "\n",
    "print(''.join([25*'-', ' Start Training ', 25*'-']))\n",
    "print(''.join([25*'-', '----------------', 25*'-']))\n",
    "alpha = 0.0001\n",
    "sigma = 1.0\n",
    "for epoch in range(parameter_dict['epochs']):\n",
    "    for batch_iter, (batch_source, batch_target) in enumerate(zip(train_data_loader, target_dataloader)):\n",
    "        # batch to GPU\n",
    "        # text\n",
    "        input_ids_source, attention_mask_source, year_ids_source, labels_source = batch_source['input_ids'].to(device), batch_source['attention_mask'].to(device), batch_source['year_ids'].to(device), batch_source['labels'].to(device)\n",
    "        input_ids_target, attention_mask_target, year_ids_target = batch_target['input_ids'].to(device), batch_target['attention_mask'].to(device), batch_target['year_ids'].to(device)\n",
    "        # after each updateing set optimzer gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs_source = bert_classification_model(input_ids=input_ids_source, attention_mask=attention_mask_source, year_ids=year_ids_source, labels = labels_source)\n",
    "        outputs_target = bert_classification_model(input_ids=input_ids_target, attention_mask=attention_mask_target, year_ids=year_ids_target)\n",
    "        hidden_states_target = outputs_target.hidden_states[0]\n",
    "        hidden_states_source = outputs_source.hidden_states[0]\n",
    "        \n",
    "        mmd_loss_value = mmd_loss(hidden_states_source, hidden_states_target, sigma)\n",
    "        # Compute the distance between the source and target distributions\n",
    "        target_dist = torch.mean(torch.exp(hidden_states_target), dim=0)\n",
    "        source_dist = torch.mean(torch.exp(hidden_states_source), dim=0)\n",
    "        \n",
    "        \"\"\"\n",
    "        the code computes the source and target distributions by taking the mean of the exponential values of the hidden states. \n",
    "        The exponential function is used to convert the hidden states into a probability distribution over the vocabulary.\n",
    "        The mean is computed along the batch dimension, resulting in a single probability distribution for each domain.\n",
    "        \"\"\"\n",
    "        distance = torch.sum(torch.abs(source_dist - target_dist))\n",
    "        \"\"\"\n",
    "        Finally, the code computes the distance between the source and target distributions using the L1 distance. \n",
    "        The L1 distance is the sum of the absolute differences between the corresponding elements of the two distributions. \n",
    "        This distance is used as a measure of how different the two domains are from each other. \n",
    "        The goal of domain adaptation is to minimize this distance, typically by adjusting the model's parameters to make it more robust to domain shift.\n",
    "        \"\"\"\n",
    "\n",
    "        # total_loss = outputs_source[0] + alpha * distance\n",
    "        \n",
    "        \"\"\"\n",
    "        The MMD loss measures the difference between the source and target domains in terms of their embeddings in a high-dimensional space defined by the Gaussian kernel.\n",
    "        The goal of the loss is to minimize this difference, which encourages the model to learn embeddings that are similar across domains.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute the total loss as a linear combination of the CE and MMD losses\n",
    "        loss = outputs_source[0] + alpha * mmd_loss_value\n",
    "        # backpropergation\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        # foward_pass_output['logits'] logits is the classifcation output\n",
    "        # before the softmax is applied --> the prediction is always the highest\n",
    "        # one.\n",
    "\n",
    "        # logging\n",
    "        training_log_dict = {\n",
    "            'training_loss': torch.mean(loss)\n",
    "            }\n",
    "\n",
    "        \n",
    "    # progress reporting \n",
    "    if batch_iter in training_milestones:\n",
    "      # save memory by not calculating a gradient\n",
    "      with torch.no_grad():\n",
    "        print(f'Epoch: {epoch}\\tBatch: {batch_iter}\\tTrain-Loss: {torch.mean(loss)}')\n",
    "    \n",
    "    # Validation:\n",
    "    # For each epoch I evaluate the model on a validation set twice. The model with \n",
    "    # the lowest (batch-wise sum) cross-entropy loss on the validation set is chosen.\n",
    "\n",
    "\n",
    "    if batch_iter in validation_milestones:\n",
    "      # set to evaluation (stop dropout)\n",
    "      bert_classification_model.eval()\n",
    "      print(''.join([25*'-', '----------------', 25*'-']))\n",
    "      print(f'Validation Run {val_run_iter} (Epoch {epoch}):')\n",
    "\n",
    "      # initaile selection cretarion.\n",
    "      sum_of_val_loss = 0\n",
    "      num_of_correct_predictions = 0\n",
    "      # loop over validation loss\n",
    "      for val_batch in validation_data_loader:\n",
    "        # permit pytroch to save gradients for the validation data since no \n",
    "        # backpropergation is not needed (save memory)\n",
    "\n",
    "        with torch.no_grad():\n",
    "         \n",
    "          # batch to GPU\n",
    "          # text\n",
    "          batch_text_inputids = val_batch['input_ids'].to(device)\n",
    "          batch_text_attention_mask = val_batch['attention_mask'].to(device)\n",
    "\n",
    "          # metadata\n",
    "          batch_yearids = val_batch['year_ids'].to(device)\n",
    "\n",
    "          #labels\n",
    "          labels = val_batch['labels'].to(device)\n",
    "    \n",
    "          # forward pass\n",
    "          forward_pass_output = bert_classification_model(input_ids=batch_text_inputids, attention_mask=batch_text_attention_mask, year_ids=batch_yearids, labels=labels)\n",
    "          loss = forward_pass_output[0]\n",
    "\n",
    "          # add batch specific loss\n",
    "          sum_of_val_loss += loss\n",
    "\n",
    "          # accuracy\n",
    "          num_of_correct_predictions += torch.sum(forward_pass_output['logits'].argmax(axis=1) == labels)\n",
    "\n",
    "      # log the loss and precision of the model\n",
    "\n",
    "      mean_loss_val = sum_of_val_loss/len(validation_torch)*1024\n",
    "      accuracy_val = num_of_correct_predictions/len(validation_torch)\n",
    "      validation_log_dict = {\n",
    "          'validation_loss': sum_of_val_loss/len(validation_torch)*1024,\n",
    "          'validation_accuracy': num_of_correct_predictions/len(validation_torch)\n",
    "        }\n",
    "\n",
    "      # print validation results\n",
    "      print(f'\\t{val_run_iter}\\n\\t Val-Loss: \\t{mean_loss_val}\\n\\t Val-Accu: \\t{accuracy_val}')\n",
    "\n",
    "      # update iter\n",
    "      val_run_iter += 1\n",
    "      # save the model if loss improved\n",
    "      if (sum_of_val_loss<sum_of_val_loss_min):\n",
    "        sum_of_val_loss_min = sum_of_val_loss\n",
    "        torch.save(bert_classification_model, f'{model_name}.pt')\n",
    "        print(''.join(['!'*25, ' New best Model ', '!'*25]))\n",
    "      \n",
    "      # print validation loss\n",
    "      print(''.join([25*'-', '----------------', 25*'-']))\n",
    "      print(f'Resume Training:')\n",
    "      # set to training (activate dropout)\n",
    "      bert_classification_model.train()\n",
    "\n",
    "# end training           \n",
    "bert_classification_model.eval() \n",
    "print('The Training took: ',time.time()-start_time, 'Seconds')\n",
    "del bert_classification_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c89017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the fine tuned model chosen on the validation set\n",
    "classification_model = torch.load((f'{model_name}.pt'), map_location=torch.device(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e5b8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-sample predictions took:  5.939906120300293 Seconds\n"
     ]
    }
   ],
   "source": [
    "# ignore dropout for testing\n",
    "classification_model.eval()\n",
    "\n",
    "# timer\n",
    "start_time = time.time()\n",
    "\n",
    "# load test data\n",
    "test_data_loader = torch.utils.data.DataLoader(test_torch, batch_size=parameter_dict['batch_size'])\n",
    "\n",
    "# numpy arrays to store predictions and true labels.\n",
    "predictions = np.array([])\n",
    "true_labels = np.array([])\n",
    "\n",
    "# train the model\n",
    "for test_batch in test_data_loader:\n",
    "\n",
    "    # I do not need gradient\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # batch to GPU\n",
    "        # text\n",
    "        batch_text_inputids = test_batch['input_ids'].to(device)\n",
    "        batch_text_attention_mask = test_batch['attention_mask'].to(device)\n",
    "\n",
    "        # metadata\n",
    "        batch_yearids = test_batch['year_ids'].to(device)\n",
    "\n",
    "        #labels\n",
    "        labels = test_batch['labels'].to(device)\n",
    "\n",
    "        # forward pass\n",
    "        foward_pass_output = classification_model(input_ids=batch_text_inputids, attention_mask=batch_text_attention_mask, year_ids=batch_yearids, labels=labels)\n",
    "        \n",
    "        # foward_pass_output['logits'] logits is the classifcation output\n",
    "        # before the softmax is applied --> the prediction is always the highest\n",
    "        # one.\n",
    "        predictions = np.append(predictions, foward_pass_output['logits'].argmax(axis=1).cpu().numpy())\n",
    "\n",
    "        # since I shuffle the batche\n",
    "        true_labels = np.append(true_labels, labels.cpu().numpy())\n",
    "\n",
    "print('Out-of-sample predictions took: ',time.time()-start_time, 'Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59ecdb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Measures Test Set:\n",
      "|    | measure   |    score |\n",
      "|---:|:----------|---------:|\n",
      "|  0 | accuracy  | 0.61875  |\n",
      "|  1 | recall    | 0.250914 |\n",
      "|  2 | precison  | 0.206538 |\n",
      "|  3 | f1_score  | 0.217989 |\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma/ma_ma/ma_ssureshb/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# model evaluations\n",
    "import tables\n",
    "Path((f'{model_name}')).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# tests\n",
    "test_statistic = dict()\n",
    "test_statistic['accuracy'] = sklearn.metrics.accuracy_score(true_labels, predictions)\n",
    "test_statistic['recall'] = sklearn.metrics.recall_score(true_labels, predictions, average='macro')\n",
    "test_statistic['precison'] = sklearn.metrics.precision_score(true_labels, predictions, average='macro')\n",
    "test_statistic['f1_score'] = sklearn.metrics.f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "# # to df and safe\n",
    "scores_df = pd.DataFrame.from_dict(test_statistic, orient='index').reset_index().rename(columns={'index': 'measure', 0: 'score'})\n",
    "scores_df.to_csv((f'{model_name}/measures_{model_name}_test.csv'), index=False)\n",
    "print(f'Evaluation Measures Test Set:\\n{scores_df.to_markdown()}\\n')\n",
    "\n",
    "# # get the confusion matrix\n",
    "# confusion_matrix = sklearn.metrics.confusion_matrix(true_labels, predictions)\n",
    "# confusion_matrix_plot = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix.astype('int'), display_labels=numerical_encoding_dict.keys())\n",
    "# confusion_matrix_plot.plot(values_format='.0f', xticks_rotation='vertical')\n",
    "# print('Confusion Matrix Test Set:')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig((f'{model_name}/confusion_matirx_{model_name}_test.png'), bbox_inches='tight', dpi=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef606e59-51d3-4d5a-8bbb-d32a5b100505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c4c7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('predictions.txt', 'w') as file:\n",
    "    for item in predictions:\n",
    "        file.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2440eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_list = list(map(int, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7e98134",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_keys = []\n",
    "\n",
    "for prediction in predictions_list:\n",
    "    for key, value in numerical_encoding_dict.items():\n",
    "        if value == prediction:\n",
    "            matched_keys.append(key)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9772b58",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (800) does not match length of index (3920)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted_Label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m matched_keys\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:3959\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3956\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3958\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3959\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:4152\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4150\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4152\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4155\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4156\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4157\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4158\u001b[0m     ):\n\u001b[1;32m   4159\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4160\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/frame.py:4878\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   4877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4878\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4879\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (800) does not match length of index (3920)"
     ]
    }
   ],
   "source": [
    "rd['Predicted_Label'] = matched_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted = rd[['rdid', 'title', 'abstract', 'date', 'year', 'Predicted_Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c35bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_predicted.to_csv(\"rd_predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9de845a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
